{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab4dee9c",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <h1>\n",
    "        <a href=\"https://github.com/modelscope/FunASR/tree/main\">实时语音识别FunASR</a>\n",
    "    </h1>\n",
    "</div>\n",
    "\n",
    "- 环境要求：**python>=3.8 torch>=1.13 torchaudio**\n",
    "- 安装依赖项\n",
    "  ```bash\n",
    "  pip3 install -U funasr\n",
    "  sudo apt-get install portaudio19-dev libportaudio2 libportaudiocpp0\n",
    "  pip install soundfile sounddevice\n",
    "  ```\n",
    "- 选用 **[paraformer-zh-streaming](https://modelscope.cn/models/iic/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-online/files)** 模型\n",
    "\n",
    "---\n",
    "\n",
    "### 1. 加载模型\n",
    "\n",
    "- 默认会去魔搭下载模型。但是从这里下载比较慢，直接去[网页](https://modelscope.cn/models/iic/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-online/files)上下载会快很多\n",
    "- 魔搭模型默认下载地址在 ~/.cache/modelscope里面\n",
    "  ```python\n",
    "  model = AutoModel(model=\"paraformer-zh-streaming\")\n",
    "  ```\n",
    "- 当然也可以填写绝对路径\n",
    "  ```python\n",
    "  model = AutoModel(model=\"/home/sumi/.cache/modelscope/hub/models/iic/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-online\")\n",
    "  ```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b50ceb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "funasr version: 1.2.6.\n"
     ]
    }
   ],
   "source": [
    "from funasr import AutoModel\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "# 全局日志设置\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "logging.getLogger(\"funasr\").setLevel(logging.ERROR)\n",
    "\n",
    "chunk_size = [0, 10, 5] #[0, 10, 5] 600ms, [0, 8, 4] 480ms\n",
    "encoder_chunk_look_back = 4 #number of chunks to lookback for encoder self-attention\n",
    "decoder_chunk_look_back = 1 #number of encoder chunks to lookback for decoder cross-attention\n",
    "\n",
    "# model = AutoModel(model=\"paraformer-zh-streaming\")\n",
    "model = AutoModel(\n",
    "    model=\"speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-online\",\n",
    "    disable_update=True,\n",
    "    disable_pbar=True,\n",
    "    disable_log=True,\n",
    "    progress_bar=False,\n",
    "    verbose=False  # 额外静默参数\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f4b150",
   "metadata": {},
   "source": [
    "### 2. 模型推理\n",
    "- 使用达摩院提供的例子代码和例子音频"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2833d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "欢迎大\n",
      "家来\n",
      "体验达\n",
      "摩院推\n",
      "出的语\n",
      "音识\n",
      "别模型\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import soundfile as sf\n",
    "import os\n",
    "\n",
    "wav_file = os.path.join(model.model_path, \"example/asr_example.wav\")\n",
    "speech, sample_rate = sf.read(wav_file)\n",
    "chunk_stride = chunk_size[1] * 960 # 600ms\n",
    "\n",
    "cache = {}\n",
    "total_chunk_num = int(len((speech)-1)/chunk_stride+1)\n",
    "for i in range(total_chunk_num):\n",
    "    speech_chunk = speech[i*chunk_stride:(i+1)*chunk_stride]\n",
    "    is_final = i == total_chunk_num - 1\n",
    "    res = model.generate(input=speech_chunk, cache=cache, \n",
    "                         is_final=is_final, chunk_size=chunk_size, \n",
    "                         encoder_chunk_look_back=encoder_chunk_look_back, \n",
    "                         decoder_chunk_look_back=decoder_chunk_look_back,\n",
    "                         disable_pbar=True,progress_bar=False,verbose=False\n",
    "                         )\n",
    "    # print(res)\n",
    "    print(res[0]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac71460a",
   "metadata": {},
   "source": [
    "### 3. 测试麦克风"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9daf595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "可用音频设备:\n",
      "   0 HDA Intel PCH: ALC1220 Analog (hw:0,0), ALSA (2 in, 6 out)\n",
      "   1 HDA Intel PCH: ALC1220 Digital (hw:0,1), ALSA (0 in, 2 out)\n",
      "   2 HDA Intel PCH: ALC1220 Alt Analog (hw:0,2), ALSA (2 in, 0 out)\n",
      "   3 HDA NVidia: HDMI 0 (hw:1,3), ALSA (0 in, 2 out)\n",
      "   4 HDA NVidia: HDMI 1 (hw:1,7), ALSA (0 in, 2 out)\n",
      "   5 HDA NVidia: HDMI 2 (hw:1,8), ALSA (0 in, 8 out)\n",
      "   6 HDA NVidia: HDMI 3 (hw:1,9), ALSA (0 in, 8 out)\n",
      "   7 HDA NVidia: HDMI 4 (hw:1,10), ALSA (0 in, 8 out)\n",
      "   8 HDA NVidia: HDMI 5 (hw:1,11), ALSA (0 in, 8 out)\n",
      "   9 HDA NVidia: HDMI 6 (hw:1,12), ALSA (0 in, 8 out)\n",
      "  10 sysdefault, ALSA (128 in, 128 out)\n",
      "  11 front, ALSA (0 in, 6 out)\n",
      "  12 surround21, ALSA (0 in, 128 out)\n",
      "  13 surround40, ALSA (0 in, 6 out)\n",
      "  14 surround41, ALSA (0 in, 128 out)\n",
      "  15 surround50, ALSA (0 in, 128 out)\n",
      "  16 surround51, ALSA (0 in, 6 out)\n",
      "  17 surround71, ALSA (0 in, 6 out)\n",
      "  18 iec958, ALSA (0 in, 2 out)\n",
      "  19 spdif, ALSA (0 in, 2 out)\n",
      "  20 samplerate, ALSA (128 in, 128 out)\n",
      "  21 speexrate, ALSA (128 in, 128 out)\n",
      "  22 pulse, ALSA (32 in, 32 out)\n",
      "  23 upmix, ALSA (8 in, 8 out)\n",
      "  24 vdownmix, ALSA (6 in, 6 out)\n",
      "  25 dmix, ALSA (0 in, 2 out)\n",
      "* 26 default, ALSA (32 in, 32 out)\n",
      "默认输入设备: {'name': 'default', 'index': 26, 'hostapi': 0, 'max_input_channels': 32, 'max_output_channels': 32, 'default_low_input_latency': 0.008684807256235827, 'default_low_output_latency': 0.008684807256235827, 'default_high_input_latency': 0.034807256235827665, 'default_high_output_latency': 0.034807256235827665, 'default_samplerate': 44100.0}\n",
      "开始录音测试，请说话...\n",
      "录音完成\n",
      "已保存到test_mic.wav，请检查文件是否有声音\n",
      "录音信息: 形状=(80000, 1), 最小值=-0.043969474732875824, 最大值=1.0867667198181152\n",
      "音频流已关闭\n"
     ]
    }
   ],
   "source": [
    "# 测试麦克风录音\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "try:\n",
    "    sd.default.reset()\n",
    "    fs = 16000  # 采样率\n",
    "    duration = 5  # 录音5秒\n",
    "\n",
    "    # 可以先测试可用的音频设备\n",
    "    print(\"可用音频设备:\")\n",
    "    print(sd.query_devices())\n",
    "    print(f\"默认输入设备: {sd.query_devices(kind='input')}\")\n",
    "\n",
    "    print(\"开始录音测试，请说话...\")\n",
    "    recording = sd.rec(int(duration * fs), samplerate=fs, channels=1)\n",
    "    sd.wait()  # 等待录音完成\n",
    "    print(\"录音完成\")\n",
    "\n",
    "    # 保存录音文件\n",
    "    sf.write('test_mic_ipynb.wav', recording, fs)\n",
    "    print(\"已保存到test_mic_ipynb.wav，请检查文件是否有声音\")\n",
    "\n",
    "    # 显示录音信息\n",
    "    print(f\"录音信息: 形状={recording.shape}, 最小值={np.min(recording)}, 最大值={np.max(recording)}\")\n",
    "finally:\n",
    "    # 关闭音频流\n",
    "    sd.stop()\n",
    "    print(\"音频流已关闭\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0fb0c5",
   "metadata": {},
   "source": [
    "### 4. 使用麦克风音频进行识别和输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a1001a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始录音，请说话...\n",
      "\n",
      "\n",
      "\n",
      "录音已停止\n"
     ]
    }
   ],
   "source": [
    "import queue\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# 配置音频参数\n",
    "FS = 16000  # 必须与模型训练采样率一致\n",
    "CHANNELS = 1\n",
    "DEVICE = None  # 使用默认设备\n",
    "\n",
    "audio_queue = queue.Queue()\n",
    "cache = {}  # 上下文缓存\n",
    "current_text = \"\"\n",
    "\n",
    "# 计算每个块的大小\n",
    "chunk_stride = chunk_size[1] * 960  # 600ms\n",
    "\n",
    "def audio_callback(indata, frames, time, status):\n",
    "    \"\"\"音频回调函数\"\"\"\n",
    "    \n",
    "    # 转换为float32格式\n",
    "    audio_data = indata.flatten().copy().astype(np.float32)\n",
    "    \n",
    "    # 如果使用int16，需要转换为模型可以处理的范围\n",
    "    if indata.dtype == np.int16:\n",
    "        audio_data = audio_data / 32768.0\n",
    "    \n",
    "    audio_queue.put(audio_data)\n",
    "\n",
    "print(\"开始录音，请说话...\\n\")\n",
    "try:\n",
    "    with sd.InputStream(\n",
    "        samplerate=FS,\n",
    "        channels=CHANNELS,\n",
    "        blocksize=chunk_stride,\n",
    "        dtype='float32',\n",
    "        device=DEVICE,\n",
    "        callback=audio_callback\n",
    "    ):\n",
    "        while True:\n",
    "            # 获取音频块\n",
    "            chunk = audio_queue.get()\n",
    "            \n",
    "            ## 调试信息\n",
    "            # signal_level = np.max(np.abs(chunk))\n",
    "            # print(f\"音频块: 形状={chunk.shape}, 信号强度={signal_level:.6f}\")\n",
    "            \n",
    "            # 执行推理\n",
    "            res = model.generate(input=chunk, cache=cache, \n",
    "                             is_final=False, chunk_size=chunk_size, \n",
    "                             encoder_chunk_look_back=encoder_chunk_look_back, \n",
    "                             decoder_chunk_look_back=decoder_chunk_look_back,\n",
    "                             disable_pbar=True, progress_bar=False, verbose=False\n",
    "                             )\n",
    "            \n",
    "            # 显示识别结果\n",
    "            if res and len(res) > 0 and 'text' in res[0] and res[0]['text']:\n",
    "                new_text = res[0]['text']\n",
    "                if new_text != current_text and new_text.strip():\n",
    "                    current_text += new_text\n",
    "                    print(current_text + \" \"*20, end=\"\\r\")  # 清除行尾\n",
    "                    sys.stdout.flush()\n",
    "            time.sleep(0.1)  # 避免CPU过载\n",
    "            \n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n\\n录音已停止\")\n",
    "except Exception as e:\n",
    "    print(f\"发生错误: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
